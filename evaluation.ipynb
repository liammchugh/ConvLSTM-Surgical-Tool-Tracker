{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"http://camma.u-strasbg.fr/\">\n",
    "<img src=\"lib/camma_logo.png\" width=\"18%\">\n",
    "</a>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Weakly-supervised ConvLSTM Surgical Tool Tracker\n",
    "================\n",
    "------\n",
    "**A re-implementation of the surgical tool tracker in** :<br>\n",
    "<i>Nwoye, C. I., Mutter, D., Marescaux, J., & Padoy, N. (2019). \n",
    "    Weakly supervised convolutional LSTM approach for tool tracking in laparoscopic videos. \n",
    "    International journal of computer assisted radiology and surgery, 14(6), 1059-1067.<br></i>\n",
    "(c) Research Group CAMMA, University of Strasbourg, France<br>\n",
    "Website: http://camma.u-strasbg.fr<br>\n",
    "Code author: Chinedu Nwoye <br>\n",
    "    \n",
    "-----\n",
    "\n",
    "The model is built using the `tf.contrib` lib. Hence, TensorFlow version > 1.15 is discouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Download code and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'ConvLSTM-Surgical-Tool-Tracker'\n",
      "c:\\Users\\liams\\Documents\\GitHub\\ProjectSurgeryHernia\\ConvLSTM-Surgical-Tool-Tracker\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/CAMMA-public/ConvLSTM-Surgical-Tool-Tracker.git\n",
    "# %cd ConvLSTM-Surgical-Tool-Tracker\n",
    "\n",
    "# print(\"Repo cloned and extracted ...\")\n",
    "\n",
    "%cd ConvLSTM-Surgical-Tool-Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Download sample video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data file...\n",
      "Data files already exist locally. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "url = 'https://s3.unistra.fr/camma_public/github/convlstm_tracker/data.zip'\n",
    "filename = 'data.zip'\n",
    "print(\"Downloading data file...\")\n",
    "# Check if data directory already exists with files\n",
    "if os.path.exists('data') and any(os.listdir('data')):\n",
    "    print(\"Data files already exist locally. Skipping download.\")\n",
    "else:\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "    print(\"Download completed. Extracting files...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "        \n",
    "    print(\"Download and extraction completed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Download model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model weights...\n",
      "Checkpoint files already exist locally. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Downloading model weights...\")\n",
    "response = requests.get('https://s3.unistra.fr/camma_public/github/convlstm_tracker/ckpt.zip', stream=True)\n",
    "# Check if checkpoint directory already exists with files\n",
    "if os.path.exists('ckpt') and any(file.endswith('.index') for file in os.listdir('ckpt') if os.path.isfile(os.path.join('ckpt', file))):\n",
    "    print(\"Checkpoint files already exist locally. Skipping download.\")\n",
    "else:\n",
    "    with open('ckpt.zip', 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "    print(\"Download completed. Extracting files...\")\n",
    "    with zipfile.ZipFile('ckpt.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "    print(\"Download and extraction completed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Some important installationns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\liams\\anaconda3\\envs\\keras_env\\lib\\site-packages (2.31.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\liams\\anaconda3\\envs\\keras_env\\lib\\site-packages (from imageio) (1.21.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\liams\\anaconda3\\envs\\keras_env\\lib\\site-packages (from imageio) (9.3.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\liams\\anaconda3\\envs\\keras_env\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\liams\\anaconda3\\envs\\keras_env\\lib\\site-packages (from imageio-ffmpeg) (65.6.3)\n",
      "Installations completed ...\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):  # colab installs tf.2.2 on default.\n",
    "    !pip uninstall -y tensorflow\n",
    "    !pip install tensorflow-gpu==1.14\n",
    "!pip install imageio\n",
    "!pip install imageio-ffmpeg\n",
    "\n",
    "print(\"Installations completed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "imports success...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tf_compat import tf\n",
    "\n",
    "\n",
    "import model\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "import sys\n",
    "from matplotlib import animation, rc, pyplot as plt\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "from IPython.display import HTML\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"imports success...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Variables & Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and device variables set .. \n"
     ]
    }
   ],
   "source": [
    "img_height   = 480 #@param {type:\"integer\"}\n",
    "img_width    = 854 #@param {type:\"integer\"}\n",
    "img_channel  = 3   #@param {type:\"integer\"}\n",
    "num_classes  = 7   #@param {type:\"integer\"}\n",
    "offset_x     = 20  #@param {type:\"integer\"}\n",
    "offset_y     = 11  #@param {type:\"integer\"}\n",
    "data_path    = 'data/surgical_video.avi' #@param {type:\"string\"} you can modify this if you evaluate on a different video\n",
    "ckpt_path    = 'ckpt' #@param {type:\"string\"}\n",
    "\n",
    "print(\"Model and device variables set .. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model blocks:  [2, 2, 2, 2]\n",
      "\tReceiving image:: (1, 480, 854, 3)\n",
      "Constructing ResNet backbone:\n",
      "\tBuilding units: conv1 -> (1, 120, 214, 64)\n",
      "\tBuilding unit: conv2_1: (1, 120, 214, 64)\n",
      "\tBuilding unit: conv2_2: (1, 120, 214, 64)\n",
      "\tBuilding unit: conv3_1: (1, 120, 214, 64)\n",
      "\tBuilding unit: conv3_2: (1, 60, 107, 128)\n",
      "\tBuilding unit: conv4_1: (1, 60, 107, 128)\n",
      "\tBuilding unit: conv4_2: (1, 60, 107, 256)\n",
      "\tBuilding unit: conv5_1: (1, 60, 107, 256)\n",
      "\tBuilding unit: conv5_2: (1, 60, 107, 512)\n",
      "\tBuilding units: ExtraNet/spatio-temporal/convlstm/convlstm: -> (1, 60, 107, 512)\n",
      "\tBuilding units: ExtraNet/FCN: -> (1, 60, 107, 7)\n",
      "Model loaded successfully...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liams\\Documents\\GitHub\\ProjectSurgeryHernia\\ConvLSTM-Surgical-Tool-Tracker\\model.py:71: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  kernel_initializer=tf.contrib.layers.variance_scaling_initializer())\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.device('/GPU:0'):  \n",
    "    img_ph  = tf.placeholder(dtype=tf.float32, shape=[None,None,3], name='inputs')\n",
    "    x       = tf.expand_dims(img_ph, 0)   \n",
    "    x       = tf.image.resize_bilinear(x, size=(480,854))             \n",
    "    seek_ph = tf.placeholder(dtype=tf.int64, shape=[None], name='inputs')\n",
    "    network = model.Model(images=x, seek=seek_ph, num_classes=num_classes)\n",
    "    logits, lhmaps  = network.build_model() \n",
    "    logits  = tf.cast(tf.round(tf.sigmoid(logits)), tf.int32)\n",
    "    lhmaps  = lhmaps * tf.cast(logits, tf.float32)\n",
    "\n",
    "print(\"Model loaded successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Saver and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from : ckpt\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"saver_and_writer\"):                  \n",
    "    saver = tf.train.Saver()  \n",
    "    state = tf.train.get_checkpoint_state(ckpt_path)\n",
    "    ckpt  = state.model_checkpoint_path\n",
    "\n",
    "print('Loading checkpoint from :',ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Evaluate on video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'ExpandDims' defined at (most recent call last):\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3029, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3472, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3552, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\liams\\AppData\\Local\\Temp\\ipykernel_10616\\1984492305.py\", line 4, in <module>\n      x       = tf.expand_dims(img_ph, 0)\nNode: 'ExpandDims'\nCannot assign a device for operation ExpandDims: {{node ExpandDims}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[ExpandDims]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation ExpandDims: {{node ExpandDims}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[ExpandDims]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10616\\3822902537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess_config\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mseek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Processing video frames\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 969\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    970\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1192\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1193\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1372\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1395\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1397\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'ExpandDims' defined at (most recent call last):\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3029, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3472, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\liams\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3552, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\liams\\AppData\\Local\\Temp\\ipykernel_10616\\1984492305.py\", line 4, in <module>\n      x       = tf.expand_dims(img_ph, 0)\nNode: 'ExpandDims'\nCannot assign a device for operation ExpandDims: {{node ExpandDims}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[ExpandDims]]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "PREDICTIONS    = []\n",
    "CLASS_LHMAPS   = []\n",
    "reader         = imageio.get_reader(data_path)\n",
    "gpu_opts = tf.GPUOptions(\n",
    "    allow_growth              = True,   # grow memory instead of pre-allocating all\n",
    "    per_process_gpu_memory_fraction = 0.95\n",
    ")\n",
    "sess_config = tf.ConfigProto(\n",
    "    gpu_options          = gpu_opts,\n",
    "    allow_soft_placement = False,       # hard-fail if an op can’t sit on GPU\n",
    "    log_device_placement = False\n",
    ")\n",
    "with tf.Session(config=sess_config) as sess:   \n",
    "    sess.run([tf.local_variables_initializer(), tf.global_variables_initializer()])\n",
    "    saver.restore(sess, ckpt)\n",
    "    for seek, frame in enumerate(tqdm(reader, desc=\"Processing video frames\")):\n",
    "        predict, lhmap = sess.run([logits, lhmaps], feed_dict={img_ph:frame, seek_ph:[seek]})\n",
    "        PREDICTIONS.append(predict)\n",
    "        CLASS_LHMAPS.append(lhmap)\n",
    "        \n",
    "print(\"Evaluation done...\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Some visualization helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates\n",
    "\n",
    "def get_center_coordinates(lhmap):\n",
    "    coord = np.where(lhmap == lhmap.max()) \n",
    "    cx    = (coord[1][0] * img_width // 107) + offset_x\n",
    "    cy    = (coord[0][0] * img_height // 60) + offset_y\n",
    "    return (cx, cy)\n",
    "\n",
    "def get_box_coordinates(lhmap):\n",
    "    coord = np.where(lhmap>0)\n",
    "    if len(coord[0])>0 and len(coord[1])>0 :\n",
    "        x0 = (coord[1].min() * img_width // 107) - offset_x\n",
    "        x1 = (coord[1].max() * img_width // 107) + offset_x\n",
    "        y0 = (coord[0].min() * img_height // 60) - offset_y\n",
    "        y1 = (coord[0].max() * img_height // 60) + offset_y\n",
    "    else:\n",
    "        x0,x1,y0,y1 = -1,-1,-1,-1\n",
    "    return (x0,y0,x1,y1)\n",
    "\n",
    "\n",
    "# Build animators\n",
    "def build_animators():\n",
    "    BUFFER_BOX_CENTER = []\n",
    "    colors    = [(255,0,0),(255,255,0),(0,0,255),(255,0,255),(255,128,0),(0,255,255),(0,255,0)] \n",
    "    radius    = 28\n",
    "    thickness = 4\n",
    "    reader    = imageio.get_reader(data_path)\n",
    "    fig       = plt.figure()\n",
    "    for k, (img, predict, lhmap) in enumerate(zip(reader, PREDICTIONS, CLASS_LHMAPS)):\n",
    "        img_overlay     = img.copy()\n",
    "        for i in range(num_classes):\n",
    "            cam         = lhmap[0,:,:,i]\n",
    "            x1,y1,x2,y2 = get_box_coordinates(cam)\n",
    "            cx,cy       = get_center_coordinates(cam)\n",
    "            color       = colors[i]\n",
    "            cv2.rectangle(img_overlay, (x1,y1), (x2,y2), color, thickness)\n",
    "            cv2.circle(img_overlay, (cx,cy), radius, color, -1)\n",
    "        cv2.circle(img_overlay, (offset_x,offset_y), radius, (0,0,0), -1)\n",
    "        BUFFER_BOX_CENTER.append([plt.imshow(img_overlay)])\n",
    "    return fig, BUFFER_BOX_CENTER\n",
    "        \n",
    "\n",
    "# Colorizer\n",
    "def cstr(s, color='black'):\n",
    "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "print(\"Model ready to track...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Tracking the video\n",
    "Build animator to display the tool trajectory (_Colormap displays the legend for the tracker_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, OVERLAY = build_animators()\n",
    "\n",
    "HTML('='*20+\"> [  Tool Colormap:                                       \"\n",
    "           +cstr(\"Grasper\", \"red\") +\" | \"+cstr(\"Bipolar\", \"yellow\") +\"  |  \"+cstr(\"Hook\", \"blue\")+\"  |  \"\n",
    "           +cstr(\"Scissors\", \"violet\")+\"  |  \" +cstr(\"Clipper\", \"orange\") \n",
    "           +\"  |  \"+cstr(\"Irrigator\", \"mouve\") +\"  |  \"+cstr(\"Specimen bag  \", \"green\")+'  ] <'+'='*20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Let's track the instruments in the video<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.ArtistAnimation(fig, OVERLAY, interval=160, blit=True, repeat_delay=1000)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
